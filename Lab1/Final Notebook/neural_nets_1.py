# -*- coding: utf-8 -*-
"""Neural_Nets_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mRYMAWLOctqv1Jtp46I0GATtFLmLXuH7

# Στοιχεία Ομάδας

**Αριθμός Ομάδας:** 66

**Ονοματεπώνυμα και ΑΜ:**

Τσιλιβής Θεόδωρος 03116032

Στόικου Θεοδότη 03117085

Ποταμίτου Νεφέλη 03117709

Dependencies:
"""

!pip install --upgrade pip  &> /dev/null#upgrade pip package installer 
!pip install scikit-learn --upgrade  &> /dev/null#upgrade scikit-learn package
!pip install numpy --upgrade  &> /dev/null#upgrade numpy package
!pip install pandas --upgrade  &> /dev/null#--upgrade #upgrade pandas package
!pip install texttable &> /dev/null

"""Imports:"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, confusion_matrix
from sklearn.svm import SVC, LinearSVC
from sklearn.dummy import DummyClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.impute import SimpleImputer
from sklearn import preprocessing
import matplotlib.pyplot as plt
from texttable import Texttable
import seaborn as sns
import time

"""# Μικρό dataset (Echocardiogram)

## Βασικές πληροφορίες

### 1. Σύντομη παρουσίαση του dataset:

Το συγκεκριμένο dataset ονομάζεται Echocardiogram και παρουσιάζει στοιχεία για την ταξινόμηση της πιθανότητας επιβίωσης ενός ασθενή, για τουλάχιστον ένα έτος, μετά από καρδιακή προσβολή.
"""

!wget "http://archive.ics.uci.edu/ml/machine-learning-databases/echocardiogram/echocardiogram.data"

"""### 2. Δειγμάτα και Χαρακτηριστικά

Τα δείγματα είναι 132 και τα χαρακτηριστικά είναι 13, όμως το 10 και το 12 μπορούν να αγνοηθούν, ενώ το 9 συνίσταται να αντικαταστήσει το 8. Όλα τα χαρακτηριστικά είναι διατεταγμένα, εκτός από το 12 (name).

### 3. Επικεφαλίδες

Δεν υπάρχουν επικεφαλίδες και η αρίθμηση γραμμών γίνεται από τη βιβλιοθήκη pandas. 
(Στην γραμμη 50 του echocardiogram.data, διαγράψτε το 1ο κομμα "," (typo), πριν τρέξετε το επόμενο cell)
"""

all_data = pd.read_csv("echocardiogram.data",delimiter = ',',header = None)
# all_data.drop([10, 11], axis=1)
data = all_data.values
data = np.delete(data, 10, 1)
data = np.delete(data, 10, 1)
data = np.delete(data, 9, 1)
data = np.delete(data, 1, 1)
data = np.delete(data, 1, 1)
print(data)
print(data.shape)

"""Το χαρακτηριστικό εξοδου (η κλάση) είναι το 13ο “alive-at-1”. Θα κρατήσετε μόνο όσα δείγματα δεν έχουν “?” στο “alive-at-1”. Τα χαρακτηριστικά είναι τα 3 έως 9 (τα υπόλοιπα μπορούν να αγνοηθούν). Η πρόβλεψη μπορεί να γίνει και με τα χαρακτηριστικά 1-9 (όπως διατυπώθηκε αρχικά) απλά θα δίνει πολύ υψηλές τιμές (που δεν προσφέρονται για πολύ περεταίρω βελτιστοποίηση) γιατί υπάρχει μεγάλη συσχέτιση (αν και όχι απόλυτη) μεταξύ των χαρακτηριστικών 1 και 2 και της μεταβλητής εξόδου. Δείτε εδώ τη συσχέτιση Pearson μεταξύ χαρακτηριστικών και εξόδου. Οι κολόνες 1-9 είναι τα χαρακτηριστικά εισόδου (έχουμε αφαιρέσει τα 3 άχρηστα αρχικά χαρακτηριστικά) και η 10η κολόνα είναι η έξοδος. Τιμές κοντά στο -1 ή στο 1 δείχνουν υψηλή συσχέτιση, αντίστροφη (-1) ή ανάλογη (1). Δείτε εδώ μια βιβλιογραφική αναφορά για τη διαχείριση του dataset.

### 4. Ετικέτες κλάσεων

Οι ετικέτες των κλάσεων βρίσκονται στο τελευταίο column (12) του dataframe. Το attribute alive-at-1 είναι boolean και δηλώνει αν ο ασθενής έχει ή όχι επιζήσει 1 χρόνο μετά την καρδιακή προσβολή (εκτός της περίπτωσης missing values, η οποία συμβολίζεται με "?").
"""

for i in range(data.shape[0]):
    print(data[i][7])

"""### 5. Μετατροπές στα αρχεία

Το αρχείο μας δίνεται κατευθείαν σε .data format και το φορτώνουμε απευθείας σε pandas dataframe.

### 6. Απουσιάζουσες τιμές και δείγματα

Υπάρχουν απουσιάζουσες τιμές. Συνολικά οι απουσιάζουσες τιμές είναι 132 και παρακάτω υπολογίζουμε τα δείγματα με απουσιάζουσες τιμές και το ποσοστό τυος επί του συνολικού πλήθους δειγμάτων.
"""

missing =0;
for i in range (data.shape[0]):
  for j in range (data.shape[1]):
    if data[i][j] == "?":
      missing = missing +1;
      break
print("Δείγματα με απουσιάζουσες τιμές:", missing)
print("Ποσοστό δειγμάτων(γραμμών) με απουσιάζουσες τιμές:", missing/data.shape[0]*100 , "%")

print("Ποσοστό δειγμάτων(γραμμών) με απουσιάζουσες τιμές:", missing/data.shape[0]*100 , "%")

"""### 7. Αριθμός κλάσεων, ποσοστά δειγμάτων και ισορροπία του dataset.

Οι κλάσεις είναι 2 (binary) και δηλώνουν αν ο ασθενής επέζησε ή όχι στον επόμενο χρόνο. Παρακάτω υπολογίζεται το πλήθος των δειγμάτων της κάθε κλάσης και το ποσοστό των δειγμάτων της επί του συνολικού πλήθους των δειγμάτων. Δεν συνυπολογίσαμε τα missing values. Το πλήθος των δειγμάτων που έχουν missing values στην κλάση είναι 132 - 58 = 74. Άρα στην κλάση 0 ανήκει το 68% και στην κλαση 1 το 32%. Άρα το dataset μπορεί να χαρακτηριστεί (οριακά) μη ισορροπημένο.
"""

zeros=0
ones=0
for i in range (data.shape[0]):
  if (data[i][7] == "0"):
    zeros = zeros +1
  elif (data[i][7] =="1"):
    ones = ones +1
print("Πλήθος δειγμάτων της κλασης 0:", zeros)
print("Ποσοστό δειγμάτων της κλάσης 0 επί του συνόλου των δειγμάτων:", zeros/data.shape[0]*100, "%")
print("Πλήθος δειγμάτων της κλασης 1:", ones)
print("Ποσοστό δειγμάτων της κλάσης 1 επί του συνόλου των δειγμάτων:", ones/data.shape[0]*100, "%")

"""### 8. Διαχωρισμός train και test set.

Σε αυτό το σημείο κάνουμε και την προεπεξεργασία. Αρχικώς αφαιρούμε από τα δεδομένα όλα τα δείγματα που έχουν ως ετικέτα "?". Στην συνέχεια στα εναπομέινοντα δείγματα τοποθετούμε στην θέση των "?" την median τιμή της κάθε στήλης. Ο λόγος που επιλέγουμε την median και όχι την average είναι για να διαφυλάξουμε binary τιμές στα binary columns.
"""

data = data[np.logical_not(data[:,7] == '?')]
data = np.where(data=="?", np.NaN, data)
# print(data[60:]) 
imp_mean = SimpleImputer(missing_values= np.NaN, strategy='median')
imp_mean.fit(data)
data = imp_mean.transform(data)
features_all = preprocessing.scale(data)[:,:7]
labels_all = data[:,7]
X_train, X_test, y_train, y_test = train_test_split(features_all, labels_all, test_size=0.2, random_state=2)

"""## Baseline Ταξινόμηση

### Help Code
"""

def Baseline_approach(classifier,X_train,X_test,y_train,y_test):
    classifier.fit(X_train,y_train)
    y_pred = classifier.predict(X_test)
    print(str(classifier),classifier.score(X_test,y_test))
    print("f1 micro score =",f1_score(y_test, y_pred, average='micro'))
    print("f1 macro score =",f1_score(y_test, y_pred, average='macro'))
    cf_matrix = confusion_matrix(y_pred,y_test)
    sns.heatmap(cf_matrix, annot=False, cmap='nipy_spectral')
    return classifier

def plot(clfs,score1,score,function,approach):
    plt.bar(clfs,score1)
    plt.title(approach + " " + score + " with " + function + " average")
    plt.savefig(approach + "_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def averaged_plots(classifierlist,X_test,y_test,approach):
    clfs  = ['Uni', 'Strat',"Freq","Prior","Con 0","Con 1", 'GNB', 'KNN']
    # [uniform,stratified,most_frequent,prior,consant_0,constant_1,GNB,Knn]
    score_micro = []
    score_macro = []
    recall_micro = []
    recall_macro = []
    precision_micro = []
    precision_macro = []
    for classifier in classifierlist:        
        y_pred = classifier.predict(X_test)
        score_micro.append(f1_score(y_test, y_pred, average = 'micro'))
        score_macro.append(f1_score(y_test, y_pred, average = 'macro'))        
        recall_micro.append(recall_score(y_test, y_pred, average = "micro"))
        recall_macro.append(recall_score(y_test, y_pred, average = "macro"))        
        precision_micro.append(precision_score(y_test, y_pred, average = 'micro'))
        precision_macro.append(precision_score(y_test, y_pred, average = 'macro'))
       

    plot(clfs,score_micro,"score","micro",approach)
    plot(clfs,score_macro,"score","macro",approach)
    plot(clfs,recall_micro,"recall","micro",approach)
    plot(clfs,recall_macro,"recall","macro",approach)
    plot(clfs,precision_micro,"precision","micro",approach)
    plot(clfs,precision_macro,"precision","macro",approach)

"""### 1. Classifiers

#### Dummy Classifiers
"""

dc_uniform = DummyClassifier(strategy="uniform")
uniform = Baseline_approach(dc_uniform,X_train,X_test,y_train,y_test)

dc_stratified = DummyClassifier(strategy="stratified")
stratified = Baseline_approach(dc_stratified,X_train,X_test,y_train,y_test)

dc_most_frequent = DummyClassifier(strategy="most_frequent")
most_frequent = Baseline_approach(dc_most_frequent,X_train,X_test,y_train,y_test)

dc_prior = DummyClassifier(strategy="prior")
prior = Baseline_approach(dc_prior,X_train,X_test,y_train,y_test)

dc_constant_0 = DummyClassifier(strategy="constant", constant = 0.0)
constant_0 = Baseline_approach(dc_constant_0,X_train,X_test,y_train,y_test)

dc_constant_1 = DummyClassifier(strategy="constant", constant = 1.0)
constant_1 = Baseline_approach(dc_constant_1,X_train,X_test,y_train,y_test)

"""#### Gaussian Naive Bayes"""

clf = GaussianNB()
GNB = Baseline_approach(clf,X_train,X_test,y_train,y_test)

"""#### kNN Classifier"""

clf = KNeighborsClassifier()
Knn = Baseline_approach(clf,X_train,X_test,y_train,y_test)

"""### 2. Averaged metric bar plots"""

classifierlist = [uniform,stratified,most_frequent,prior,constant_0,constant_1,GNB,Knn]
averaged_plots(classifierlist,X_test,y_test,"Baseline")

"""### 3. Precision, Recall, F1 Scores

Στους αξιοσημείωτους classifiers (GNB, Knn) παρατηρούμε πως οι τιμές των precision και recall  δεν αλλάζουν πολύ. Τόσο το precision όσο το recall και το score είναι αρκετά ψηλά (μεγαλύτερα της τάξης του 80%) και απλώς σε micro averaging έχουμε λίγο μεγαλύτερες τιμές από ότι σε macro averaging.

## Βελτιστοποίηση ταξινομητών (micro)

Σε αυτό το απόσπασμα αξιολογούμε τις βέλτιστες παραμέτρους και την επιρροή τους στις επιδόσεις των ταξινομητών.

### Help Code
"""

def grid_search(clf,parameters,X_train,X_test,y_train,y_test,verbose = 10,scoring = "f1_micro"):
    clf = GridSearchCV(clf,parameters, n_jobs = -1, cv = 10, verbose = verbose ,scoring = scoring)
    clf.fit(X_train,y_train)
    print(clf.best_estimator_)
    Best_clf = clf.best_estimator_.fit(X_train,y_train)
    print(Best_clf.score(X_test,y_test))
    return Best_clf

def Best_approach(classifier,X_train,X_test,y_train,y_test):
    classifier.fit(X_train,y_train)
    y_pred = classifier.predict(X_test)
    print(str(classifier),classifier.score(X_test,y_test))
    print("f1 micro score =",f1_score(y_test, y_pred, average='micro'))
    cf_matrix = confusion_matrix(y_pred,y_test)
    sns.heatmap(cf_matrix, annot=False, cmap='nipy_spectral')
    return classifier

def best_plot(clfs,score1,score,function,approach):
    plt.bar(clfs,score1)
    plt.title(approach + " " + score + " with " + function + " average")
    plt.savefig(approach + "_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def best_averaged_plots(classifierlist,X_test,y_test,approach):
    clfs  = ['GNB','KNN']
    score_micro = []
    score_macro = []
    recall_micro = []
    recall_macro = []
    precision_micro = []
    precision_macro = []
    for classifier in classifierlist:        
        y_pred = classifier.predict(X_test)
        score_micro.append(f1_score(y_test, y_pred, average = 'micro'))
        recall_micro.append(recall_score(y_test, y_pred, average = "micro"))
        precision_micro.append(precision_score(y_test, y_pred, average = 'micro'))
       

    best_plot(clfs,score_micro,"score","micro",approach)
    best_plot(clfs,recall_micro,"recall","micro",approach)
    best_plot(clfs,precision_micro,"precision","micro",approach)

def difference_plot(clfs,score1,score,function,approach):
    plt.bar([1-.25/2],score1[0],width = .25)
    plt.bar([1+.25/2],score1[1],width = .25)
    plt.xticks([1],clfs)
    plt.title(approach + " for " + score + " with " + function + " average")
    plt.savefig(approach + "_for_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def difference_averaged_plots(classifierlist,bestclassifierlist,X_test,y_test,approach):
    clfs  = ['KNN']
    score_micro = [[],[]]
    score_macro = [[],[]]
    recall_micro = [[],[]]
    recall_macro = [[],[]]
    precision_micro = [[],[]]
    precision_macro = [[],[]]
    for i in range(1):
        base_y_pred = classifierlist[i].predict(X_test)
        best_y_pred = bestclassifierlist[i].predict(X_test)
        score_micro[0].append(f1_score(y_test, base_y_pred, average = 'micro'))
        recall_micro[0].append(recall_score(y_test, base_y_pred, average = "micro"))
        precision_micro[0].append(precision_score(y_test, base_y_pred, average = 'micro'))
        score_micro[1].append(f1_score(y_test, best_y_pred, average = 'micro'))
        recall_micro[1].append(recall_score(y_test, best_y_pred, average = "micro"))
        precision_micro[1].append(precision_score(y_test, best_y_pred, average = 'micro'))

    difference_plot(clfs,score_micro,"score","micro",approach)
    difference_plot(clfs,recall_micro,"recall","micro",approach)
    difference_plot(clfs,precision_micro,"precision","micro",approach)

"""### 1. Classifiers

#### kΝΝ Classifier
Hyperparameters: n_neighbors.

Βέλτιστες παράμετροι πρόκευψαν :


*   n_neighbors = 8



Score = 0.9333333333333333
"""

parameters =  {"n_neighbors": [i + 1 for i in range(10)]}
clf = KNeighborsClassifier(n_jobs = -1)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

best_Knn = KNeighborsClassifier(n_neighbors = 8, n_jobs = -1)
Knn = Baseline_approach(best_Knn,X_train,X_test,y_train,y_test)

"""### 2. Final fit and running time"""

t = Texttable()

fit_times = []
predict_times = []
table = [['Classifier','Fit time (s)','Predict time (s)', 'Score']]
classifiernames = ["GNB","Knn"]
GNB = GaussianNB()
best_knn = KNeighborsClassifier(n_neighbors = 8, n_jobs = -1)
bestclassifierlist = [GNB,best_knn]

i = 0
for clf in bestclassifierlist:
    point1 = time.time()
    clf.fit(X_train,y_train)
    point2 = time.time()
    y_pred = clf.predict(X_test)
    point3 = time.time()
    fit_times.append(round(point2 - point1,8))
    predict_times.append(round(point3-point2,5))
    table.append([classifiernames[i],round(point2 - point1,8),round(point3-point2,8),clf.score(X_test,y_test)])

    i += 1

t.add_rows(table)
print(t.draw())

"""### 3. Averaged metric bar plots

Δεν τυπώνουμε για τους dummy καθώς δεν έχουν ποιοτικό ενδιαφέρον.
"""

best_averaged_plots(bestclassifierlist,X_test,y_test,"Best")

"""### 4. Before And After Optimization"""

difference_averaged_plots(classifierlist[7:],bestclassifierlist[1:],X_test,y_test,"Difference")

"""### 5. Precision, Recall, F1 Scores, and more

Με fine tuning καταφέρνουμε να ανεβάσουμε την επίδοση του ταξινομητή Knn τόσο ώστε να φτάνει και τον GNB στο score (93.3%) για την μετρική F1_micro. Παρατηρούμε και πάλι πώς έχουμε περίπου ίδιες τιμές precision και recall .

## Βελτιστοποίηση ταξινομητών (macro)

Σε αυτό το απόσπασμα αξιολογούμε τις βέλτιστες παραμέτρους και την επιρροή τους στις επιδόσεις των ταξινομητών.

### Help Code
"""

def grid_search(clf,parameters,X_train,X_test,y_train,y_test,verbose = 10,scoring = "f1_macro"):
    clf = GridSearchCV(clf,parameters, n_jobs = -1, cv = 10, verbose = verbose ,scoring = "f1_macro")
    clf.fit(X_train,y_train)
    print(clf.best_estimator_)
    Best_clf = clf.best_estimator_.fit(X_train,y_train)
    print(Best_clf.score(X_test,y_test))
    return Best_clf

def Best_approach(classifier,X_train,X_test,y_train,y_test):
    classifier.fit(X_train,y_train)
    y_pred = classifier.predict(X_test)
    print(str(classifier),classifier.score(X_test,y_test))
    print("f1 micro score =",f1_score(y_test, y_pred, average='micro'))
    print("f1 macro score =",f1_score(y_test, y_pred, average='macro'))
    cf_matrix = confusion_matrix(y_pred,y_test)
    sns.heatmap(cf_matrix, annot=False, cmap='nipy_spectral')
    return classifier

def best_plot(clfs,score1,score,function,approach):
    plt.bar(clfs,score1)
    plt.title(approach + " " + score + " with " + function + " average")
    plt.savefig(approach + "_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def best_averaged_plots(classifierlist,X_test,y_test,approach):
    clfs  = ['GNB','KNN']
    score_micro = []
    score_macro = []
    recall_micro = []
    recall_macro = []
    precision_micro = []
    precision_macro = []
    for classifier in classifierlist:        
        y_pred = classifier.predict(X_test)
        score_macro.append(f1_score(y_test, y_pred, average = 'macro'))        
        recall_macro.append(recall_score(y_test, y_pred, average = "macro"))        
        precision_macro.append(precision_score(y_test, y_pred, average = 'macro'))
       

    best_plot(clfs,score_macro,"score","macro",approach)
    best_plot(clfs,recall_macro,"recall","macro",approach)
    best_plot(clfs,precision_macro,"precision","macro",approach)

def difference_plot(clfs,score1,score,function,approach):
    plt.bar([1-.25/2],score1[0],width = .25)
    plt.bar([1+.25/2],score1[1],width = .25)
    plt.xticks([1],clfs)
    plt.title(approach + " for " + score + " with " + function + " average")
    plt.savefig(approach + "_for_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def difference_averaged_plots(classifierlist,bestclassifierlist,X_test,y_test,approach):
    clfs  = ['KNN']
    score_micro = [[],[]]
    score_macro = [[],[]]
    recall_micro = [[],[]]
    recall_macro = [[],[]]
    precision_micro = [[],[]]
    precision_macro = [[],[]]
    for i in range(1):
        base_y_pred = classifierlist[i].predict(X_test)
        best_y_pred = bestclassifierlist[i].predict(X_test)
        score_macro[0].append(f1_score(y_test, base_y_pred, average = 'macro'))        
        recall_macro[0].append(recall_score(y_test, base_y_pred, average = "macro"))        
        precision_macro[0].append(precision_score(y_test, base_y_pred, average = 'macro'))
        score_macro[1].append(f1_score(y_test, best_y_pred, average = 'macro'))        
        recall_macro[1].append(recall_score(y_test, best_y_pred, average = "macro"))        
        precision_macro[1].append(precision_score(y_test, best_y_pred, average = 'macro'))

    difference_plot(clfs,score_macro,"score","macro",approach)
    difference_plot(clfs,recall_macro,"recall","macro",approach)
    difference_plot(clfs,precision_macro,"precision","macro",approach)

"""### 1. Classifiers

#### kΝΝ Classifier
Hyperparameters: n_neighbors.

Βέλτιστες παράμετροι πρόκευψαν :


*   n_neighbors = 5



Score = 0.9068322981366459
"""

parameters =  {"n_neighbors": [i for i in range(10)]}
clf = KNeighborsClassifier(n_jobs = -1)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

best_Knn = KNeighborsClassifier(n_neighbors = 8, n_jobs = -1)
Knn = Baseline_approach(best_Knn,X_train,X_test,y_train,y_test)

"""### 2. Final fit and running time"""

t = Texttable()

fit_times = []
predict_times = []
table = [['Classifier','Fit time (s)','Predict time (s)', 'Score']]
classifiernames = ["GNB","Knn"]
GNB = GaussianNB()
best_knn = KNeighborsClassifier(n_neighbors = 8, n_jobs = -1)
bestclassifierlist = [GNB,best_knn]

i = 0
for clf in bestclassifierlist:
    point1 = time.time()
    clf.fit(X_train,y_train)
    point2 = time.time()
    y_pred = clf.predict(X_test)
    point3 = time.time()
    fit_times.append(round(point2 - point1,8))
    predict_times.append(round(point3-point2,5))
    table.append([classifiernames[i],round(point2 - point1,8),round(point3-point2,8),clf.score(X_test,y_test)])

    i += 1

t.add_rows(table)
print(t.draw())

"""### 3. Averaged metric bar plots

Δεν τυπώνουμε για τους dummy καθώς δεν έχουν ποιοτικό ενδιαφέρον.
"""

best_averaged_plots(bestclassifierlist,X_test,y_test,"Best")

"""### 4. Before And After Optimization"""

difference_averaged_plots(classifierlist[7:],bestclassifierlist[1:],X_test,y_test,"Difference")

"""### 5. Precision, Recall, F1 Scores, and more

Με fine tuning βελτιώνουμε τον Knn αλγόριθμος ώστε να έχει την ίδια συμπεριφορά με τον GNB (ποσοτικά, με διαφορετικά test δεδομένα θα διέφεραν). Παρατηρούμε και πάλι πώς έχουμε περίπου ίδιες τιμές precision και recall.

# Μεγάλο dataset (ISOLET)

## Βασικές πληροφορίες

### 1. Σύντομη παρουσίαση του dataset:

Το classification task είναι η ταξινόμηση ονόματος-γράμματος από σήμα φωνής. Το dataset προέκυψε από 150 ανθρώπους οι οποίοι διάβασαν ολογογράφως τα γράμματα του Αγγλικού αλφαβήτου από 2 φορές το καθένα.
"""

!wget "http://archive.ics.uci.edu/ml/machine-learning-databases/isolet/isolet1+2+3+4.data.Z" &> /dev/null
!wget "http://archive.ics.uci.edu/ml/machine-learning-databases/isolet/isolet5.data.Z" &> /dev/null

!gzip -d -f *.Z &> /dev/null

"""### 2. Δειγμάτα και Χαρακτηριστικά

Το συγκεκριμένο dataset είναι ήδη χωρισμένο σε train και test data. Έχουμε 6238 train samples και 1559 test samples, σύνολο άρα 7797. Το κάθε δείγμα περιλαμβάνει 617 features τα οποία είναι όλα αριθμητικές τιμές. Τα features αυτά προέκυψαν από διαφορετικές αναλύσεις όπως:
*italicized text*
*   Spectral coefficients,
*   Contour features,
*   Sonorant features,
*   Pre-sonorant features,
*   Post-sonorant features.





"""

train_data = pd.read_csv("isolet1+2+3+4.data", header=None)
print(train_data.shape)

test_data = pd.read_csv("isolet5.data", header=None)
print(test_data.shape)
# test_data.head()

"""### 3. Επικεφαλίδες

Δεν υπάρχουν επικεφαλίδες και η αρίθμηση γραμμών γίνεται από τη βιβλιοθήκη pandas. 
"""

train_data.head()

"""### 4. Ετικέτες κλάσεων 

Οι ετικέτες των κλάσεψων βρίσκονται στο τελευταίο column (617) του dataframe. Τα δεδομένα είναι με την σειρά και άρα τα labels τα βλέπουμε να εμβανίζονται με την σειρά ως 
1.   1.0 (δηλαδή Alpha)
2.   2.0 (δηλαδή Beta)

 ...

26. 26.0 (δηλαδή Zed)


"""

print(train_data[:][617])

"""### 5. Μετατροπές στα αρχεία

 Τα αρχεία δίνοντα σε .Z compress format και με αποσυμπίεση λαμβάνουμε αρχεία σε .data format. Αυτό συνεπάγεται πως δεν χρειάζεται να κάνουμε κάποια μετατροπή.

### 6. Απουσιάζουσες τιμές και δείγματα

Στο dataset μας έχουν απορριφθεί 3 από τα αρχικά δείγματα με αποτέλεσμα το πλήθος των δειγμάτων μας να είναι 7797 έναντι του 7800  
( 150 άνθρωποι * 52 αναγνώσεις γραμμάτων). Δεν υπάρχουν αποσιάζουσες τιμές. Αξίζει να σημειωθεί πως έχουμε ήδη κανονικοποιημένες όλες τις τιμές των χαρακτηριτικών.

### 7. Αριθμός κλάσεων, ποσοστά δειγμάτων και ισορροπία του dataset.

Σε ακολουθία των παραπάνω καταννούμε ότι οι κλάσεις είναι 26, όσα τα γράμματα του λατινικού αλφαβήτου, ο αριθμός των δείγματων κάθε κλάσης είναι περίπου ίσος ( δίοτι όπως αναφέραμε 3 δείγματα δεν συμπεριλήφθηκαν) και άρα το dataset είναι ισορροπημένο. Συγκεκριμένα προκύπτουν οι εξής πληθικότητες στο dataset:
"""

features_train = train_data.iloc[:, :617]
features_train = features_train.values

labels_train = train_data.iloc[:, [617]]
labels_train = labels_train.values[:,0]

features_test = test_data.iloc[:, :617]
features_test = features_test.values

labels_test = test_data.iloc[:, [617]]
labels_test = labels_test.values[:,0]

unique1, counts1 = np.unique(labels_train, return_counts=True)
unique2, counts2 = np.unique(labels_test, return_counts=True)

print("Dict with key the letter-associated number and value the multiplicity of the class in the dataset")
dict(zip(unique1, counts1 + counts2))

"""### 8. Διαχωρισμός train και test set.

Τα δεδομένα μας έχουν ήδη δωθεί χωρισμένα σε train και test. Όμως δεν ικανοποιούνται οι απαιτήσεις μας για τον % χωρισμό του dataset. Συγκεκριμένα ο υπάρχον χωρισμός δίνει 80% train set ενώ θέλουμε 70%. Τα χωρίζουμε λοιπόν με τυχαίο τρόπο.
"""

X_all = np.concatenate((features_train,features_test))
y_all = np.concatenate((labels_train,labels_test))
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.3, random_state = 5)

"""##Baseline Classification

Σε αυτό το απόσπασμα εξετάζουμε το πρόβλημα χωρίς την εύρεση βέλτιστων παραμέτρων.

### Help Code
"""

def Baseline_approach(classifier,X_train,X_test,y_train,y_test):
    classifier.fit(X_train,y_train)
    y_pred = classifier.predict(X_test)
    print(str(classifier),classifier.score(X_test,y_test))
    print("f1 micro score =",f1_score(y_test, y_pred, average='micro'))
    print("f1 macro score =",f1_score(y_test, y_pred, average='macro'))
    # print(confusion_matrix(y_pred,y_test))
    cf_matrix = confusion_matrix(y_pred,y_test)
    sns.heatmap(cf_matrix, annot=False, cmap='nipy_spectral')
    return classifier

def plot(clfs,score1,score,function,approach):
    plt.bar(clfs,score1)
    plt.title(approach + " " + score + " with " + function + " average")
    plt.savefig(approach + "_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def averaged_plots(classifierlist,X_test,y_test,approach):
    clfs  = ['Uniform', 'Stratified', 'GNB', 'KNN', 'MLP', 'SVM', 'LinearSVM']
    score_micro = []
    score_macro = []
    recall_micro = []
    recall_macro = []
    precision_micro = []
    precision_macro = []
    for classifier in classifierlist:        
        y_pred = classifier.predict(X_test)
        score_micro.append(f1_score(y_test, y_pred, average = 'micro'))
        score_macro.append(f1_score(y_test, y_pred, average = 'macro'))        
        recall_micro.append(recall_score(y_test, y_pred, average = "micro"))
        recall_macro.append(recall_score(y_test, y_pred, average = "macro"))        
        precision_micro.append(precision_score(y_test, y_pred, average = 'micro'))
        precision_macro.append(precision_score(y_test, y_pred, average = 'macro'))
       

    plot(clfs,score_micro,"score","micro",approach)
    plot(clfs,score_macro,"score","macro",approach)
    plot(clfs,recall_micro,"recall","micro",approach)
    plot(clfs,recall_macro,"recall","macro",approach)
    plot(clfs,precision_micro,"precision","micro",approach)
    plot(clfs,precision_macro,"precision","macro",approach)

"""### 1. Classifiers

#### Dummy Classifiers
"""

dc_uniform = DummyClassifier(strategy="uniform")
uniform = Baseline_approach(dc_uniform,X_train,X_test,y_train,y_test)

dc_stratified = DummyClassifier(strategy="stratified")
stratified = Baseline_approach(dc_stratified,X_train,X_test,y_train,y_test)

"""#### Gaussian Naive Bayes Classifier

"""

classifier = GaussianNB()
GNB = Baseline_approach(classifier,X_train,X_test,y_train,y_test)

"""#### kΝΝ Classifier
Default τιμές: K = 5
"""

classifier = KNeighborsClassifier(n_jobs = -1)
Knn = Baseline_approach(classifier,X_train,X_test,y_train,y_test)

"""#### Multi-Layer Perceptron (MLP)

Default τιμές: activation = relu , size = 100, alpha = .0001, learning rate = 'constant', solver = 'adam'
"""

classifier = MLPClassifier()
MLP = Baseline_approach(classifier,X_train,X_test,y_train,y_test)

"""#### Support Vector Machines (SVM)

Default τιμές nonLinear: kernel = 'rbf', C = 1, gamma = scale, degree = 3, tol = 0.001.

Default τιμές Linear: loss =  'squared_hinge', tol = 0.0001, C = 1.
"""

classifier = SVC()
SVM = Baseline_approach(classifier,X_train,X_test,y_train,y_test)

classifier = LinearSVC(dual = False)
linearSVM = Baseline_approach(classifier,X_train,X_test,y_train,y_test)

"""### 2. Averaged metric bar plots"""

classifierlist = [uniform,stratified,GNB,Knn,MLP,SVM,linearSVM]
averaged_plots(classifierlist,X_test,y_test,"Baseline")

"""### 3. Precision, Recall, F1 Scores

Ακόμα και χωρίς fine tuning το task μας φαίνεται πως είναι αρκετά απλό. Παρατηρούμε πώς στους περισσότερους ταξινομητές τόσο σε micro όσο και se macro level έχουμε τα περίπου τα ίδια precision και recall. Αυτό είναι αναμενόμενο διότι είναι εξίσου πιθανό να κάνεις λάθος δύο γράμματα μεταξύ τους, δηλαδή π.χ. το να θεωρήσεις το m ως n και το n ως m είναι περίπου ισοπίθανο (αυτό φαίνεται και από την συμμετρία των confusion matrix). Οι επιδόσεις των αξιόλογων ταξινομητών ξεκινούν από το 79% και φτάνουν έως και 96%

## Βελτιστοποίηση ταξινομητών (micro)

Σε αυτό το απόσπασμα αξιολογούμε τις βέλτιστες παραμέτρους και την επιρροή τους στις επιδόσεις των ταξινομητών.

### Help Code
"""

def grid_search(clf,parameters,X_train,X_test,y_train,y_test,verbose = 10,scoring = "fi_micro"):
    clf = GridSearchCV(clf,parameters, n_jobs = -1, cv = 10, verbose = verbose ,scoring = "f1_micro")
    clf.fit(X_train,y_train)
    print(clf.best_estimator_)
    Best_clf = clf.best_estimator_.fit(X_train,y_train)
    print(Best_clf.score(X_test,y_test))
    return Best_clf

def Best_approach(classifier,X_train,X_test,y_train,y_test):
    classifier.fit(X_train,y_train)
    y_pred = classifier.predict(X_test)
    print(str(classifier),classifier.score(X_test,y_test))
    print("f1 micro score =",f1_score(y_test, y_pred, average='micro'))
    print("f1 macro score =",f1_score(y_test, y_pred, average='macro'))
    # print(confusion_matrix(y_pred,y_test))
    cf_matrix = confusion_matrix(y_pred,y_test)
    sns.heatmap(cf_matrix, annot=False, cmap='nipy_spectral')
    return classifier

def best_plot(clfs,score1,score,function,approach):
    plt.bar(clfs,score1)
    plt.title(approach + " " + score + " with " + function + " average")
    plt.savefig(approach + "_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def best_averaged_plots(classifierlist,X_test,y_test,approach):
    clfs  = ['KNN', 'MLP', 'SVM', 'LinearSVM']
    score_micro = []
    score_macro = []
    recall_micro = []
    recall_macro = []
    precision_micro = []
    precision_macro = []
    for classifier in classifierlist:        
        y_pred = classifier.predict(X_test)
        score_micro.append(f1_score(y_test, y_pred, average = 'micro'))
        recall_micro.append(recall_score(y_test, y_pred, average = "micro"))
        precision_micro.append(precision_score(y_test, y_pred, average = 'micro'))
       

    best_plot(clfs,score_micro,"score","micro",approach)
    best_plot(clfs,recall_micro,"recall","micro",approach)
    best_plot(clfs,precision_micro,"precision","micro",approach)

def difference_plot(clfs,score1,score,function,approach):
    plt.bar([1-.25/2, 2-.25/2, 3-.25/2, 4-.25/2],score1[0],width = .25)
    plt.bar([1+.25/2, 2+.25/2, 3+.25/2, 4+.25/2],score1[1],width = .25)
    plt.xticks([1,2,3,4],clfs)
    plt.title(approach + " for " + score + " with " + function + " average")
    plt.savefig(approach + "_for_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def difference_averaged_plots(classifierlist,bestclassifierlist,X_test,y_test,approach):
    clfs  = ['KNN', 'MLP', 'SVM', 'LinearSVM']
    score_micro = [[],[]]
    score_macro = [[],[]]
    recall_micro = [[],[]]
    recall_macro = [[],[]]
    precision_micro = [[],[]]
    precision_macro = [[],[]]
    for i in range(4):
        base_y_pred = classifierlist[i].predict(X_test)
        best_y_pred = bestclassifierlist[i].predict(X_test)
        score_micro[0].append(f1_score(y_test, base_y_pred, average = 'micro'))
        recall_micro[0].append(recall_score(y_test, base_y_pred, average = "micro"))
        precision_micro[0].append(precision_score(y_test, base_y_pred, average = 'micro'))
        score_micro[1].append(f1_score(y_test, best_y_pred, average = 'micro'))
        recall_micro[1].append(recall_score(y_test, best_y_pred, average = "micro"))
        precision_micro[1].append(precision_score(y_test, best_y_pred, average = 'micro'))

    difference_plot(clfs,score_micro,"score","micro",approach)
    difference_plot(clfs,recall_micro,"recall","micro",approach)
    difference_plot(clfs,precision_micro,"precision","micro",approach)

"""### 1. Classifiers

#### kΝΝ Classifier

Hyperparameters: n_neighbors, metric, weights.

Βέλτιστες παράμετροι πρόκευψαν :


*   n_neighbors = 7
*   metric = euclidean
*   weights = distance


Score = 0.9064102564102564
"""

parameters =  {'metric':('euclidean', 'manhattan', 'chebyshev'), 'weights':("uniform","distance"), "n_neighbors": [1, 3, 5, 7]}
clf = KNeighborsClassifier(n_jobs = -1)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

best_knn = KNeighborsClassifier(n_neighbors = 7 , metric = 'euclidean', weights = "distance", n_jobs = -1)
_ = Baseline_approach(best_knn, X_train,X_test,y_train,y_test)

"""#### Multi-Layer Perceptron (MLP)

Hyperparameters: hidden_layer_sizes, activation, solver, max_iter, learning_rate, alpha.

Βέλτιστοι παράμετροι προέκυψαν οι εξής:
*   activation = relu 
*   alpha = 0.0001
*   hidden_layer_sizes = 128
*   learning_rate = constant
*   max_iter = 200
*   solver = adam

Accuracy = 0.9666666666666667

Για την βελτιστοποιηση του MLP αρχικώς δοκιμάσαμε ένα ευρύ gridsearch και στην συνέχεια αφού επιλέξαμε ορισμένες μεταβλητές ως αρχικοποίηση τρέξαμε από ένα gridsearch για κάθε επιμέρους παράμετρο. Αυτο το κάναμε διότι έτρεχε εξαντλητικά αργά η εκπαίδευση του νευρωνικού
"""

parameters =  {'hidden_layer_sizes':[8,16], "activation": ('logistic', 'tanh', 'relu'), "solver": ("lbfgs", "sgd", "adam"), "max_iter": [100, 200], "learning_rate": ('constant', 'invscaling'), "alpha": [.001,.0001]}
clf = MLPClassifier()

grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

parameters =  {'hidden_layer_sizes':[8,16,32,64,128,256,512]}
clf = MLPClassifier(activation='relu',solver='adam',max_iter=200,learning_rate='invscaling',alpha=.0001)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

parameters =  {'learning_rate':('constant','invscaling')}
clf = MLPClassifier(hidden_layer_sizes = 128, activation='relu',solver='adam',max_iter=200,alpha=.0001)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

parameters =  {'max_iter':[100,200,400]}
clf = MLPClassifier(hidden_layer_sizes = 128, activation='relu',learning_rate='constant',solver='adam',alpha=.0001)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

parameters =  {"alpha": [0,.001,.0001] }
clf = MLPClassifier(hidden_layer_sizes = 128, activation='relu',learning_rate='constant',solver='adam',max_iter = 200)
grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

best_MLP = MLPClassifier(activation = 'relu' , alpha = 0.0001, hidden_layer_sizes = 128, max_iter = 200, learning_rate = "constant", solver = 'adam')
_ = Baseline_approach(best_MLP, X_train,X_test,y_train,y_test)

"""#### Support Vector Machines (SVM)

##### Linear Kernel:

Hyperparameters: loss, tol, C.

Βέλτιστοι παράμετροι προέκυψαν οι εξής:

*   loss = squared_hinge
*   tol = 0.0001
*   C = 0.1

Accuracy = 0.958974358974359
"""

clf = LinearSVC(dual = False)
parameters = {'loss': ('hinge', 'squared_hinge'), 'tol': [0,.001,.0001], 'C': [.1,1,10]}
grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

best_Linearsvm = LinearSVC(loss = 'squared_hinge',tol = 0.0001,C = .1 ,dual = False)
_ = Baseline_approach(best_Linearsvm, X_train,X_test,y_train,y_test)

"""##### Poly & Rbf Kernels: 

Hyperparameters: kernel, C, degree, gamma, tol

Βέλτιστοι παράμετροι προέκυψαν οι εξής:

*   kernel = rbf
*   C = 10
*   tol = 0.001
*   degree = 2
*   gamma = scale

Accuracy = 0.9722222222222222
"""

clf = SVC()
parameters = {'kernel': ('poly’', 'rbf'), 'degree': [2,3,4],"gamma": ('scale', 'auto'), 'tol': [.001,.0001], 'C': [.1,1,10]}
grid_search(clf,parameters,X_train,X_test,y_train,y_test,10)

best_svm = SVC(kernel = 'rbf',tol = 0.001, C = 10,degree = 2, gamma = 'scale' )
_ = Baseline_approach(best_svm, X_train,X_test,y_train,y_test)

"""### 2. Final fit and running time

Αναμένουμε μεγάλο χρόνο εκπαίδευσης στο νευρωνικό και τις δύο μεθόδους SVM, ενώ μεγάλο χρόνο εκτέλεσης στην μέθοδο Knn. Οι χρόνοι εκτέλεσης εκπαίδευσης και πρόβλεψης των βέλιστων classifiers προκύπτουν:
"""

t = Texttable()

fit_times = []
predict_times = []
table = [['Classifier','Fit time (s)','Predict time (s)', 'Score']]
classifiernames = ["GNB","Knn","MLP","SVM","LinearSVM"]
GNB = GaussianNB()
best_knn = KNeighborsClassifier(n_neighbors = 7 , metric = 'euclidean', weights = "distance", n_jobs = -1)
best_mlp = MLPClassifier(activation = "relu", alpha = 0.0001, hidden_layer_sizes = 128, learning_rate = "constant", max_iter = 200, solver = "adam")
best_Linearsvm =  LinearSVC(loss = 'squared_hinge', tol = 0.0001, C = .1, dual = False)
best_Svm = SVC(kernel = 'rbf', C = 10, tol = .001, degree = 2, gamma = 'scale')
bestclassifierlist = [GNB,best_knn,best_mlp,best_Svm,best_Linearsvm]

i = 0
for clf in bestclassifierlist:
    point1 = time.time()
    clf.fit(X_train,y_train)
    point2 = time.time()
    y_pred = clf.predict(X_test)
    point3 = time.time()
    fit_times.append(round(point2 - point1,3))
    predict_times.append(round(point3-point2,3))
    table.append([classifiernames[i],round(point2 - point1,3),round(point3-point2,3),clf.score(X_test,y_test)])

    i += 1

t.add_rows(table)
print(t.draw())

"""### 3. Averaged metric bar plots"""

best_averaged_plots(bestclassifierlist[1:],X_test,y_test,"Best")

"""### 4. Before And After Optimization"""

difference_averaged_plots(classifierlist[3:],bestclassifierlist[1:],X_test,y_test,"Difference")

"""### 5. Precision, Recall, F1 Scores, and more

Όπως σχολιάσαμε και προηγουμένως το classification πρόβλημα που αντιμετωπίζουμε είναι αρκετά εύκολο. Με fine tuning καταφέρνουμε να ανεβάσουμε τις επιδόσεις των ταξινομητών σε ποσοστό της τάξης του 0.5%. Παρατηρούμε και πάλι πώς έχουμε περίπου ίδιες τιμές precision και recall. Οι επιδόσεις των βέλτιστων ταξινομητών ξεκινούν από το 80% και φτάνουν έως και 97%

## Βελτιστοποίηση ταξινομητών (macro)

Σε αυτό το απόσπασμα αξιολογούμε τις βέλτιστες παραμέτρους και την επιρροή τους στις επιδόσεις των ταξινομητών.

### Help Code
"""

def grid_search(clf,parameters,X_train,X_test,y_train,y_test,verbose = 10, scoring = 'f1_macro'):
    clf = GridSearchCV(clf,parameters, n_jobs = -1, cv = 5, verbose = verbose, scoring = "f1_macro")
    clf.fit(X_train,y_train)
    print(clf.best_estimator_)
    Best_clf = clf.best_estimator_.fit(X_train,y_train)
    y_pred = Best_clf.predict(X_test)
    print(f1_score(y_test,y_pred,average = 'macro'))
    # print(Best_clf.score(X_test,y_test))
    return Best_clf

def Best_approach(classifier,X_train,X_test,y_train,y_test):
    classifier.fit(X_train,y_train)
    y_pred = classifier.predict(X_test)
    print(str(classifier),classifier.score(X_test,y_test))
    print("f1 micro score =",f1_score(y_test, y_pred, average='micro'))
    print("f1 macro score =",f1_score(y_test, y_pred, average='macro'))
    # print(confusion_matrix(y_pred,y_test))
    cf_matrix = confusion_matrix(y_pred,y_test)
    sns.heatmap(cf_matrix, annot=False, cmap='nipy_spectral')
    return classifier

def best_plot(clfs,score1,score,function,approach):
    plt.bar(clfs,score1)
    plt.title(approach + " " + score + " with " + function + " average")
    plt.savefig(approach + "_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def best_averaged_plots(classifierlist,X_test,y_test,approach):
    clfs  = ['KNN', 'MLP', 'SVM', 'LinearSVM']
    score_micro = []
    score_macro = []
    recall_micro = []
    recall_macro = []
    precision_micro = []
    precision_macro = []
    for classifier in classifierlist:        
        y_pred = classifier.predict(X_test)
        score_macro.append(f1_score(y_test, y_pred, average = 'macro'))        
        recall_macro.append(recall_score(y_test, y_pred, average = "macro"))        
        precision_macro.append(precision_score(y_test, y_pred, average = 'macro'))
       

    best_plot(clfs,score_macro,"score","macro",approach)
    best_plot(clfs,recall_macro,"recall","macro",approach)
    best_plot(clfs,precision_macro,"precision","macro",approach)

def difference_plot(clfs,score1,score,function,approach):
    plt.bar([1-.25/2, 2-.25/2, 3-.25/2, 4-.25/2],score1[0],width = .25)
    plt.bar([1+.25/2, 2+.25/2, 3+.25/2, 4+.25/2],score1[1],width = .25)
    plt.xticks([1,2,3,4],clfs)
    plt.title(approach + " for " + score + " with " + function + " average")
    plt.savefig(approach + "_for_" + score + "_with_"+ function + "_average.jpg")
    plt.show()

def difference_averaged_plots(classifierlist,bestclassifierlist,X_test,y_test,approach):
    clfs  = ['KNN', 'MLP', 'SVM', 'LinearSVM']
    score_micro = [[],[]]
    score_macro = [[],[]]
    recall_micro = [[],[]]
    recall_macro = [[],[]]
    precision_micro = [[],[]]
    precision_macro = [[],[]]
    for i in range(4):
        base_y_pred = classifierlist[i].predict(X_test)
        best_y_pred = bestclassifierlist[i].predict(X_test)
        score_macro[0].append(f1_score(y_test, base_y_pred, average = 'macro'))        
        recall_macro[0].append(recall_score(y_test, base_y_pred, average = "macro"))        
        precision_macro[0].append(precision_score(y_test, base_y_pred, average = 'macro'))
        score_macro[1].append(f1_score(y_test, best_y_pred, average = 'macro'))        
        recall_macro[1].append(recall_score(y_test, best_y_pred, average = "macro"))        
        precision_macro[1].append(precision_score(y_test, best_y_pred, average = 'macro'))

    difference_plot(clfs,score_macro,"score","macro",approach)
    difference_plot(clfs,recall_macro,"recall","macro",approach)
    difference_plot(clfs,precision_macro,"precision","macro",approach)

"""### 1. Classifiers

#### kΝΝ Classifier

Hyperparameters: n_neighbors, metric, weights.

Βέλτιστες παράμετροι πρόκευψαν :


*   n_neighbors = 7
*   metric = euclidean
*   weights = distance


Accuracy = 0.9055599300249125
"""

parameters =  {'metric':('euclidean', 'manhattan', 'chebyshev'), 'weights':("uniform","distance"), "n_neighbors": [1, 3, 5, 7]}
clf = KNeighborsClassifier(n_jobs = -1)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,5,)

best_knn = KNeighborsClassifier(n_neighbors = 7 , metric = 'euclidean', weights = "distance", n_jobs = -1)
_ = Baseline_approach(best_knn, X_train,X_test,y_train,y_test)

"""#### Multi-Layer Perceptron (MLP)

Hyperparameters: hidden_layer_sizes, activation, solver, max_iter, learning_rate, alpha.

Βέλτιστοι παράμετροι προέκυψαν οι εξής:
*   activation = relu 
*   alpha = 0.001
*   hidden_layer_sizes = 256
*   learning_rate = constant
*   max_iter = 200
*   solver = adam

Accuracy = 0.9649033431544065

Για την βελτιστοποιηση του MLP αρχικώς δοκιμάσαμε ένα ευρύ gridsearch και στην συνέχεια αφού επιλέξαμε ορισμένες μεταβλητές ως αρχικοποίηση τρέξαμε από ένα gridsearch για κάθε επιμέρους παράμετρο. Αυτο το κάναμε διότι έτρεχε εξαντλητικά αργά η εκπαίδευση του νευρωνικού
"""

parameters =  {'hidden_layer_sizes':[8,16], "activation": ('logistic', 'tanh', 'relu'), "solver": ("lbfgs", "sgd", "adam"), "max_iter": [100, 200], "learning_rate": ('constant', 'invscaling'), "alpha": [.001,.0001]}
clf = MLPClassifier()

grid_search(clf,parameters,X_train,X_test,y_train,y_test,5)

parameters =  {'hidden_layer_sizes':[8,16,32,64,128,256,512]}
clf = MLPClassifier(activation='relu',solver='adam',max_iter=200,learning_rate='invscaling',alpha=.0001)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,5)

parameters =  {'learning_rate':('constant','invscaling')}
clf = MLPClassifier(hidden_layer_sizes = 256, activation='relu',solver='adam',max_iter=200,alpha=.0001)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,5,)

parameters =  {'max_iter':[100,200,400]}
clf = MLPClassifier(hidden_layer_sizes = 256, activation='relu',learning_rate='invscaling',solver='adam',alpha=.0001)

grid_search(clf,parameters,X_train,X_test,y_train,y_test,5)

parameters =  {"alpha": [0,.001,.0001] }
clf = MLPClassifier(hidden_layer_sizes = 256, activation='relu',learning_rate='constant',solver='adam',max_iter = 200)
grid_search(clf,parameters,X_train,X_test,y_train,y_test,5)

best_MLP = MLPClassifier(alpha = 0.0001, hidden_layer_sizes = 256, activation='relu', learning_rate='constant', solver='adam', max_iter = 200)
_ = Baseline_approach(best_MLP, X_train,X_test,y_train,y_test)

"""#### Support Vector Machines (SVM)

##### Linear Kernel:

Hyperparameters: loss, tol, C.

Βέλτιστοι παράμετροι προέκυψαν οι εξής:

*   loss = squared_hinge
*   tol = 0.0001
*   C = 0.1

Accuracy = 0.958544359919671
"""

clf = LinearSVC(dual = False)
parameters = {'loss': ('hinge', 'squared_hinge'), 'tol': [0,.001,.0001], 'C': [.1,1,10]}
grid_search(clf,parameters,X_train,X_test,y_train,y_test,5)

best_Linearsvm = LinearSVC(loss = 'squared_hinge',tol = 0.0001,C = .1 ,dual = False)
_ = Baseline_approach(best_Linearsvm, X_train,X_test,y_train,y_test)

"""##### Poly & Rbf Kernels: 

Hyperparameters: kernel, C, degree, gamma, tol

Βέλτιστοι παράμετροι προέκυψαν οι εξής:

*   kernel = rbf
*   C = 10
*   tol = 0.001
*   degree = 2
*   gamma = scale

Accuracy = 0.972449275377252
"""

clf = SVC()
parameters = {'kernel': ('poly’', 'rbf'), 'degree': [2,3,4],"gamma": ('scale', 'auto'), 'tol': [.001,.0001], 'C': [.1,1,10]}
grid_search(clf,parameters,X_train,X_test,y_train,y_test,5)

best_svm = SVC(kernel = 'rbf',tol = 0.001, C = 10, degree = 2, gamma = 'scale' )
_ = Baseline_approach(best_svm, X_train,X_test,y_train,y_test)

"""### 2. Final fit and running time

Αναμένουμε μεγάλο χρόνο εκπαίδευσης στο νευρωνικό και τις δύο μεθόδους SVM, ενώ μεγάλο χρόνο εκτέλεσης στην μέθοδο Knn. Οι χρόνοι εκτέλεσης εκπαίδευσης και πρόβλεψης των βέλιστων classifiers προκύπτουν:
"""

t = Texttable()

fit_times = []
predict_times = []
table = [['Classifier','Fit time (s)','Predict time (s)', 'Score']]
classifiernames = ["GNB","Knn","MLP","SVM","LinearSVM"]
GNB = GaussianNB()
best_knn = KNeighborsClassifier(n_neighbors = 7 , metric = 'euclidean', weights = "distance", n_jobs = -1)
best_mlp = MLPClassifier(alpha = 0.0001, hidden_layer_sizes = 256, activation='relu', learning_rate='constant', solver='adam', max_iter = 200)
best_Linearsvm =  LinearSVC(loss = 'squared_hinge', tol = 0.0001, C = .1, dual = False)
best_Svm = SVC(kernel = 'rbf', C = 10, tol = .001, degree = 2, gamma = 'scale')
bestclassifierlist = [GNB,best_knn,best_mlp,best_Svm,best_Linearsvm]

i = 0
for clf in bestclassifierlist:
    point1 = time.time()
    clf.fit(X_train,y_train)
    point2 = time.time()
    y_pred = clf.predict(X_test)
    point3 = time.time()
    fit_times.append(round(point2 - point1,3))
    predict_times.append(round(point3-point2,3))
    table.append([classifiernames[i],round(point2 - point1,3),round(point3-point2,3),clf.score(X_test,y_test)])

    i += 1

t.add_rows(table)
print(t.draw())

"""### 3. Averaged metric bar plots"""

best_averaged_plots(bestclassifierlist[1:],X_test,y_test,"Best")

"""### 4. Before And After Optimization"""

difference_averaged_plots(classifierlist[3:],bestclassifierlist[1:],X_test,y_test,"Difference")

"""### 5. Precision, Recall, F1 Scores, and more

Όπως σχολιάσαμε και προηγουμένως το classification πρόβλημα που αντιμετωπίζουμε είναι αρκετά εύκολο. Με fine tuning καταφέρνουμε να ανεβάσουμε τις επιδόσεις των ταξινομητών σε ποσοστό της τάξης του 0.5%. Παρατηρούμε και πάλι πώς έχουμε περίπου ίδιες τιμές precision και recall. Οι επιδόσεις των βέλτιστων ταξινομητών ξεκινούν από το 80% και φτάνουν έως και 97%
"""